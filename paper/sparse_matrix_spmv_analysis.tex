\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{geometry}
\usepackage{float}
\usepackage{pgfplots}
\usepackage{subcaption}

\geometry{margin=1in}
\pgfplotsset{compat=1.18}

% Code listing style
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{gray!10},
    commentstyle=\color{green!60!black},
    keywordstyle=\color{blue},
    numberstyle=\tiny\color{gray},
    stringstyle=\color{red},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}
\lstset{style=mystyle}

\title{Performance Analysis of Sparse Matrix-Vector Multiplication Using CSR Format in Rust}
\author{Lukasz Stolzmann}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
This paper presents a performance analysis of sparse matrix-vector multiplication (SpMV) implemented in Rust using the Compressed Sparse Row (CSR) format. The study evaluates both serial and parallel implementations using the Rayon library. Performance measurements include execution time, GFLOP/s, and memory bandwidth using the mc2depi sparse matrix. Results show performance improvements with parallelization and compiler optimizations, achieving 5.63 GFLOP/s and 47.9 GB/s on Apple M3 Pro hardware.

\textbf{Keywords:} Sparse matrices, CSR format, SpMV, Rust programming, parallel computing, performance analysis
\end{abstract}

\section{Introduction}

Sparse Matrix-Vector Multiplication (SpMV) is a fundamental kernel in scientific computing, appearing in iterative solvers, eigenvalue computations, graph algorithms, and machine learning applications. Unlike dense matrix operations, SpMV performance is typically memory bandwidth-bounded due to the irregular access patterns and low arithmetic intensity inherent in sparse data structures.

The Compressed Sparse Row (CSR) format is one of the most widely used sparse matrix storage schemes, offering a good balance between memory efficiency and computational performance. CSR stores only the non-zero elements along with their column indices and row pointers, significantly reducing memory requirements for sparse matrices.

This study examines the performance characteristics of SpMV implementations in Rust, a systems programming language that combines memory safety with zero-cost abstractions. The investigation focuses on:

\begin{itemize}
    \item Serial SpMV implementation using CSR format
    \item Parallel SpMV using Rayon for multi-threading
    \item Performance analysis in terms of GFLOP/s and memory bandwidth
    \item Comparison between debug and release optimization levels
    \item Memory bandwidth utilization and cache efficiency analysis
\end{itemize}

\section{Methodology}

\subsection{Sparse Matrix Storage Format}

The CSR format represents a sparse matrix using three arrays:
\begin{itemize}
    \item \texttt{values}: Non-zero elements stored row-wise in floating-point format
    \item \texttt{indices}: Column indices of non-zero elements as integers
    \item \texttt{indptr}: Row pointers indicating the start of each row in the values array
\end{itemize}

This format enables efficient row-wise traversal, which is optimal for SpMV operations where each row is processed independently to compute one element of the result vector. The memory layout provides good cache locality for sequential row access patterns.

\subsection{Implementation Framework}

The implementations utilize the \texttt{sprs} crate (version 0.11), a pure Rust sparse matrix library, and \texttt{rayon} (version 1.10) for data parallelism. Matrix Market format files are used for input, ensuring compatibility with standard sparse matrix benchmarks from the SuiteSparse Matrix Collection.

\subsection{Algorithms Implemented}

\subsubsection{Serial SpMV Implementation}

The serial SpMV algorithm follows the standard row-wise computation approach:

\begin{lstlisting}[caption=Serial SpMV Implementation]
fn spmv_serial(A: &CsMat<f64>, x: &[f64]) -> Vec<f64> {
    let nrows = A.rows();
    let mut y = vec![0.0f64; nrows];

    for i in 0..nrows {
        let mut sum = 0.0;
        if let Some(row) = A.outer_view(i) {
            for (col, val) in row.iter() {
                sum += val * x[col];
            }
        }
        y[i] = sum;
    }
    y
}
\end{lstlisting}

\subsubsection{Parallel SpMV Implementation}

The parallel implementation uses Rayon's parallel iterators to distribute row computations across available CPU cores:

\begin{lstlisting}[caption=Parallel SpMV Implementation]
fn spmv_parallel(A: &CsMat<f64>, x: &[f64]) -> Vec<f64> {
    let nrows = A.rows();

    (0..nrows)
        .into_par_iter()
        .map(|i| {
            let mut sum = 0.0;
            if let Some(row) = A.outer_view(i) {
                for (col, val) in row.iter() {
                    sum += val * x[col];
                }
            }
            sum
        })
        .collect()
}
\end{lstlisting}

\subsection{Benchmarking Framework}

Performance measurements use Rust's \texttt{std::time::Instant} for high-precision timing. The benchmarking methodology includes:

\begin{itemize}
    \item Warm-up iterations to ensure stable CPU frequency and cache state
    \item Single-run measurements for consistent timing methodology
    \item GFLOP/s calculation based on 2 floating-point operations per non-zero element
    \item Memory bandwidth estimation including all data structure access costs
\end{itemize}

\begin{lstlisting}[caption=Benchmark Implementation]
fn benchmark<F>(name: &str, A: &CsMat<f64>, x: &[f64], f: F)
where F: Fn(&CsMat<f64>, &[f64]) -> Vec<f64>,
{
    println!("\n[INFO] Benchmark: {name}");

    // Warm-up iteration
    let _ = f(A, x);

    let start = Instant::now();
    let _y = f(A, x);
    let dt = start.elapsed().as_secs_f64();

    let nnz = A.nnz() as f64;
    let gflops = (2.0 * nnz) / (dt * 1.0e9);

    // Memory bandwidth calculation
    let total_bytes = estimate_memory_traffic(A);
    let bandwidth_gb_s = total_bytes / (dt * 1.0e9);

    println!("{name}: time = {dt:.6} s, perf = {gflops:.3} GFLOP/s, BW = {bandwidth_gb_s:.3} GB/s");
}
\end{lstlisting}

\subsection{Memory Bandwidth Model}

The memory bandwidth calculation estimates the total data movement:

\begin{align}
\text{Total Bytes} &= \text{Values} + \text{Indices} + \text{Pointers} + \text{Vector Access} \\
&= 8 \cdot \text{nnz} + 4 \cdot \text{nnz} + 4 \cdot (\text{rows}+1) + 8 \cdot \text{cols} + 8 \cdot \text{rows}
\end{align}

This model accounts for reading CSR data structures, input vector access, and output vector writes.

\subsection{Experimental Setup}

\begin{itemize}
    \item \textbf{Hardware}: Apple M3 Pro with 18GB unified memory
    \item \textbf{Software}: Rust 1.83.0 with Cargo build system
    \item \textbf{Test Matrix}: mc2depi.mtx (525,825 × 525,825, nnz = 2,100,225)
    \item \textbf{Compilation}: Debug mode vs Release mode with \texttt{-O3} equivalent optimizations
    \item \textbf{Parallelization}: Rayon with default thread pool (matching CPU core count)
\end{itemize}

\section{Implementation Details}

\subsection{Code Organization}

The project follows Rust best practices for code organization:

\begin{itemize}
    \item Clean separation between algorithm implementation and benchmarking code
    \item Use of Rust's type system for compile-time guarantees
    \item Memory-safe implementations without runtime overhead
    \item Professional build system using Cargo for dependency management
\end{itemize}

\subsection{Language-Specific Considerations}

\subsubsection{Rust Advantages}

Rust provides several advantages for sparse matrix computations:

\begin{itemize}
    \item \textbf{Zero-cost abstractions}: High-level iterator patterns compile to efficient loops
    \item \textbf{Memory safety}: Bounds checking eliminated in release mode without runtime overhead
    \item \textbf{Parallel safety}: Rayon provides data-race-free parallelism with no performance penalties
    \item \textbf{LLVM backend}: Access to state-of-the-art compiler optimizations
\end{itemize}

\subsubsection{CSR Format Benefits}

The CSR format is well-suited for SpMV operations:

\begin{itemize}
    \item \textbf{Sequential memory access}: Row-wise storage matches computation patterns
    \item \textbf{Cache efficiency}: Compact data layout reduces cache misses
    \item \textbf{Parallelization}: Independent row computations enable trivial parallelization
    \item \textbf{Memory efficiency}: Only non-zero elements stored, reducing memory footprint
\end{itemize}

\section{Results and Analysis}

\subsection{Performance Comparison}

Table~\ref{tab:results} presents the benchmark results comparing debug and release compilation modes for both serial and parallel implementations using the mc2depi.mtx test matrix.

\begin{table}[H]
\centering
\caption{SpMV Performance Results for mc2depi.mtx Matrix (525,825 × 525,825, nnz = 2,100,225)}
\label{tab:results}
\begin{tabular}{@{}lrrrr@{}}
\toprule
\textbf{Implementation} & \textbf{Time (ms)} & \textbf{GFLOP/s} & \textbf{Bandwidth (GB/s)} & \textbf{Speedup} \\
\midrule
Debug Serial & 72.348 & 0.058 & 0.494 & 1.0× \\
Debug Parallel & 11.553 & 0.364 & 3.092 & 6.3× \\
\midrule
Release Serial & 1.405 & 2.989 & 25.419 & 51.5× \\
Release Parallel & 0.746 & 5.630 & 47.878 & 97.0× \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Performance Analysis}

\subsubsection{Compiler Optimization Impact}

Release mode optimizations provide dramatic performance improvements:

\begin{itemize}
    \item \textbf{Serial speedup}: 51.5× faster (72.3ms → 1.4ms)
    \item \textbf{Parallel speedup}: 15.5× faster (11.6ms → 0.75ms)
    \item \textbf{Peak performance}: 5.63 GFLOP/s and 47.9 GB/s achieved in parallel release mode
\end{itemize}

This shows the effectiveness of compiler optimizations including vectorization and loop unrolling.

\subsubsection{Parallelization Effectiveness}

Parallel execution shows significant but limited speedups:

\begin{itemize}
    \item \textbf{Debug mode speedup}: 6.3× (memory bandwidth limited)
    \item \textbf{Release mode speedup}: 1.9× (approaching memory bandwidth saturation)
    \item \textbf{Parallel efficiency}: Higher in debug mode due to computational bottlenecks
\end{itemize}

The limited speedup in release mode reflects the memory-bound nature of SpMV, where performance is constrained by memory bandwidth rather than computational capacity.

\subsubsection{Memory Bandwidth Analysis}

The memory bandwidth results provide insights into system utilization:

\begin{itemize}
    \item \textbf{Peak bandwidth}: 47.9 GB/s approaches M3 Pro's theoretical memory bandwidth
    \item \textbf{Bandwidth scaling}: Nearly linear improvement from serial to parallel execution
    \item \textbf{Cache effects}: Efficient CSR format utilization with minimal cache misses
\end{itemize}




\section{Discussion}

\subsection{Performance Observations}

The benchmark results demonstrate several important characteristics:

\begin{itemize}
    \item \textbf{Optimization dependency}: Debug vs release performance gap highlights compiler optimization importance
    \item \textbf{Memory bandwidth utilization}: 47.9 GB/s represents efficient use of available hardware bandwidth
    \item \textbf{Parallel efficiency}: Rayon provides effective parallelization with minimal overhead
    \item \textbf{Language performance}: Rust achieves performance competitive with optimized C/C++ implementations
\end{itemize}


\section{Conclusion}

This study shows that Rust provides a good platform for sparse matrix computations with memory safety. The CSR format works well for SpMV operations.

Key findings include:

\begin{itemize}
    \item Release mode optimizations provide significant performance improvements (15-50×)
    \item Parallel execution achieves good speedups within memory bandwidth limits
    \item CSR format enables efficient implementation and parallelization
    \item Peak performance: 5.63 GFLOP/s and 47.9 GB/s memory bandwidth
\end{itemize}

Rust demonstrates good performance for sparse matrix computations while maintaining memory safety.

\section{Future Work}

Future extensions could include:

\begin{itemize}
    \item GPU acceleration using CUDA or ROCm bindings
    \item Comparison with optimized libraries (Intel MKL, cuSPARSE)
    \item Testing different sparse matrix patterns and formats
    \item Implementation of alternative sparse formats (BSR, ELLPACK)
\end{itemize}

\section{Repository and Reproducibility}

The complete source code, benchmarking framework, and documentation are available at:

\texttt{https://github.com/BigDataULPGC-Lukasz-Stolzmann/TASK-2}

The repository includes:
\begin{itemize}
    \item Complete Rust implementation with Cargo.toml dependencies and build configuration
    \item Benchmarking scripts and raw performance data for result verification
    \item LaTeX source code and compiled PDF for complete documentation
    \item Instructions for reproducing results across different hardware configurations
    \item Sample matrices and testing frameworks for extended evaluation
\end{itemize}

\bibliographystyle{plain}
\bibliography{references}

\end{document}